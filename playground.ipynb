{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO per Valentina\n",
    "\n",
    "- go through the files she sent on Teams\n",
    "- think once again whats how to improve actions identification - still does mistakes\n",
    "- Make possible to query two files at once\n",
    "- get some information on where the fuck does she want to publish?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import load_models\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from questioning import load_qdf, ask_qdfs, pdfs_to_documents, documents_to_vector_store, query_action_detail, query_action_SMART, query_action_list, ask_RAG, filter_action_pages\n",
    "\n",
    "from logging_config import logging_config\n",
    "logger = logging_config(f'GPT@JRC','logger.log')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from prompts import PROMPTS\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "config = {\n",
    "    'Torino':{\n",
    "        'pdfs': [\n",
    "            {'file':'Torino.pdf','action_page_limit': (143, 191)}\n",
    "        ],\n",
    "    },\n",
    "    'Zaragoza':{\n",
    "        'pdfs': [\n",
    "            {'file':'Zaragoza.pdf','action_page_limit': (0, 200)}\n",
    "        ],\n",
    "    },\n",
    "    'Bologna':{\n",
    "        'pdfs': [\n",
    "            {'file':'Bologna.pdf','action_page_limit': (128, 194)}\n",
    "        ],\n",
    "    },\n",
    "    'Izmir':{\n",
    "        'pdfs': [\n",
    "            {'file':'Izmir.pdf','action_page_limit': (58, 142)}\n",
    "        ],\n",
    "    },\n",
    "    'Lisbon':{\n",
    "        'pdfs': [\n",
    "            {'file':'Lisbon_1.pdf','action_page_limit': (0, 200)},\n",
    "            {'file':'Lisbon_2.pdf','action_page_limit': (0, 200)}\n",
    "        ],\n",
    "    },\n",
    "    'Liepaja':{\n",
    "        'pdfs': [\n",
    "            {'file':'Liepaja_1.pdf','action_page_limit': (60, 100)},\n",
    "            #{'file':'Liepaja_2.pdf','action_page_limit': (0, 200)} # seem to be old version\n",
    "        ],\n",
    "    },\n",
    "    'Valencia':{\n",
    "        'pdfs': [\n",
    "            {'file':'Valencia_1.pdf','action_page_limit': (0, 200)},\n",
    "            {'file':'Valencia_2.pdf','action_page_limit': (0, 200)}\n",
    "        ],\n",
    "    },\n",
    "    'Porto':{\n",
    "        'pdfs': [\n",
    "            {'file':'Porto_1.pdf','action_page_limit': (0, 200)},\n",
    "            {'file':'Porto_2.pdf','action_page_limit': (0, 200)}\n",
    "        ],\n",
    "    },\n",
    "    'Lappeenranta':{\n",
    "        'pdfs': [\n",
    "            {'file':'Lappeenranta.pdf','action_page_limit': (0, 200)}\n",
    "            \n",
    "        ],\n",
    "    },\n",
    "    'Firenze':{\n",
    "        'pdfs': [\n",
    "            {'file':'Firenze.pdf','action_page_limit': (45, 87)},\n",
    "        ],\n",
    "    },\n",
    "    'Ioannina':{\n",
    "        'pdfs': [\n",
    "            {'file':'Ioannina.pdf','action_page_limit': (75, 125)}\n",
    "        ]\n",
    "    },\n",
    "    'Kalamata':{\n",
    "        'pdfs': [\n",
    "            {'file':'Kalamata.pdf','action_page_limit': (78, 122)}\n",
    "        ]\n",
    "    },\n",
    "    'Tampere':{\n",
    "        'pdfs': [\n",
    "            {'file':'Tampere.pdf','action_page_limit': (28, 62)}\n",
    "        ],\n",
    "    },\n",
    "    'Espoo':{\n",
    "        'pdfs': [\n",
    "            {'file':'Espoo.pdf','action_page_limit': (30, 88)}\n",
    "        ],\n",
    "    },\n",
    "    'Guimaraes':{\n",
    "        'pdfs': [\n",
    "            {'file':'Guimaraes.pdf','action_page_limit': (226, 282)}\n",
    "        ]\n",
    "    },\n",
    "    'Lahti':{\n",
    "        'pdfs': [\n",
    "            {'file':'Lahti.pdf','action_page_limit': (12, 35)}\n",
    "        ],\n",
    "    },\n",
    "    'Kozani':{\n",
    "        'pdfs': [\n",
    "            {'file':'Kozani.pdf','action_page_limit': (250, 443)}\n",
    "        ],\n",
    "    },\n",
    "    'Pecs':{\n",
    "        'pdfs': [\n",
    "            {'file':'Pecs.pdf','action_page_limit': (30, 78)}\n",
    "        ],\n",
    "    },\n",
    "    'Sevilla':{\n",
    "        'pdfs': [\n",
    "            {'file':'Sevilla.pdf','action_page_limit': (190, 300)}\n",
    "        ],\n",
    "    },\n",
    "    'Turku':{\n",
    "        'pdfs': [\n",
    "            {'file':'Turku.pdf','action_page_limit': (10, 55)}\n",
    "        ],\n",
    "    },\n",
    "    'Leuven':{\n",
    "        'pdfs': [\n",
    "            {'file':'Leuven.pdf','action_page_limit': (17, 51)}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "load_dotenv()\n",
    "llm, emb = load_models(service = 'DeepInfra')\n",
    "qdf = load_qdf() # questions from JSON\n",
    "pdf_prefix='pdf_input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 15:14:21,842 - GPT@JRC - INFO - Starting PDFs of Firenze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Questions: 100%|██████████| 58/58 [13:14<00:00, 13.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 15:28:09,981 - GPT@JRC - INFO - Action list...\n",
      "2025-01-28 15:33:00,134 - GPT@JRC - INFO - Action details...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action details: 100%|██████████| 35/35 [31:45<00:00, 54.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-28 16:04:45,715 - GPT@JRC - INFO - Action SMARTs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action SMART: 100%|██████████| 35/35 [07:27<00:00, 12.79s/it]\n"
     ]
    }
   ],
   "source": [
    "def pdf_to_excel(city, excel_output, llm=llm, emb=emb, pdf_prefix='pdf_input/',config=config):\n",
    "    files = [f'{pdf_prefix}{pdf[\"file\"]}' for pdf in config[city]['pdfs']]\n",
    "\n",
    "    logger.info(f'Starting PDFs of {city}')    \n",
    "    logger.debug('Reading the documents..')\n",
    "    documents, splits = pdfs_to_documents(files)\n",
    "    \n",
    "    logger.debug('Converting to vector store ...')\n",
    "    vector_store = documents_to_vector_store(documents, emb)\n",
    "\n",
    "    with pd.ExcelWriter(excel_output) as xlsx:\n",
    "\n",
    "        qs_responses = ask_qdfs(\n",
    "            qdf = qdf,\n",
    "            llm = llm, \n",
    "            vector_store = vector_store,\n",
    "            city = city,\n",
    "            logger=logger\n",
    "        )\n",
    "\n",
    "        qs_responses.to_excel(xlsx,sheet_name='standard_qs')\n",
    "\n",
    "        logger.debug('Barriers...')\n",
    "\n",
    "        class Barrier(BaseModel):\n",
    "            title: str\n",
    "            brief_description: str\n",
    "            page_reference: str\n",
    "            explanation: str\n",
    "            category: List[Literal[\"Leadership\", \"Financial\", \"Regulatory\", \"Operational\", \"Organisational\", \"Partnerships\", \"Social\", \"Environmental\", \"Safety and Security\", \"Other\"]]\n",
    "        \n",
    "        class BarrierList(BaseModel):\n",
    "            barriers: List[Barrier]\n",
    "\n",
    "\n",
    "        response = ask_RAG(\n",
    "            embed_query = '''Identify text segments that describe obstacles, limitations, or difficulties in implementing the SECAP or achieving emission reduction targets. \n",
    "            Focus on segments describing: \"barrier\", \"challenge\", \"weakness\", \"lack of\", \"difficulty/difficulties\", \"insufficient/insufficiency\", \"inadequate/inadequacy\",\n",
    "            \"failure\", \"underestimation\", \"burden\" when they specifically relate to plan implementation or target achievement. \n",
    "            \n",
    "            Exclude mentions of barriers that only apply to specific individual actions.''',\n",
    "            vector_store = vector_store,\n",
    "            response_model=BarrierList,\n",
    "            llm = llm,\n",
    "            logger = logger,\n",
    "            template_key = 'barriers_prompt',\n",
    "            template_kwargs={},\n",
    "            city = city,\n",
    "            k=50\n",
    "        )\n",
    "        bars = pd.DataFrame([b for b in response['barriers']])\n",
    "        bars.to_excel(xlsx, sheet_name = 'barriers')\n",
    "\n",
    "        logger.debug('Participatory processes...')\n",
    "\n",
    "        class Stakeholder(BaseModel):\n",
    "            stakeholder: str\n",
    "            role: str\n",
    "\n",
    "        class ParticipatoryProcess(BaseModel):\n",
    "            title: str\n",
    "            brief_description: str = Field(description=\"Description in English\")\n",
    "            page_reference: str\n",
    "            explanation: str\n",
    "            relevant_stakeholders: List[Stakeholder]\n",
    "            implementation_barriers: Optional[List[str]] = []\n",
    "            barriers_solution: Optional[List[str]] = []\n",
    "            citizen_contribution_clearly_defined: bool\n",
    "\n",
    "        class ParticipatoryProcesses(BaseModel):\n",
    "            participatory_processes: List[ParticipatoryProcess]\n",
    "\n",
    "\n",
    "        response = ask_RAG(\n",
    "            embed_query='''\n",
    "            1. Identify sections that describe formal participatory processes using terms like: \"consultation\", \"workshop\", \"public hearing\", \"stakeholder meeting\", \"engagement process\", \"participatory planning\", \"co-creation\"\n",
    "            2. Identify text segments describing specific mechanisms for citizen input such as: \"feedback\", \"survey\", \"questionnaire\", \"public comment\", \"citizen proposal\", \"voting\", \"participatory budgeting\"\n",
    "            3. Identify descriptions of stakeholder groups and their roles using terms like: \"working group\", \"advisory board\", \"steering committee\", \"citizen panel\", \"focus group\", \"community representative\"\n",
    "            4. Identify segments discussing challenges or limitations in public participation using terms like: \"barrier\", \"challenge\", \"limitation\", \"difficulty\", \"low participation\", \"engagement gap\"            ''',\n",
    "            template_key='participatory_processes',\n",
    "            template_kwargs={},\n",
    "            response_model=ParticipatoryProcesses,\n",
    "            vector_store=vector_store,\n",
    "            llm=llm,\n",
    "            logger=logger,\n",
    "            city=city,\n",
    "            k=50\n",
    "        )\n",
    "\n",
    "        participatory_processes = pd.DataFrame([pp for pp in response['participatory_processes']])\n",
    "        participatory_processes.to_excel(xlsx, sheet_name='participatory_processes')\n",
    "\n",
    "        logger.info(f'Action list...')\n",
    "\n",
    "        action_list = query_action_list(\n",
    "            llm=llm, \n",
    "            documents=filter_action_pages(splits, config[city]),\n",
    "            logger=logger\n",
    "        )\n",
    "\n",
    "        logger.info(f'Action details...')\n",
    "        ads = [query_action_detail(\n",
    "                action=action, \n",
    "                llm=llm, \n",
    "                vector_store=vector_store, \n",
    "                logger=logger,\n",
    "                city = city\n",
    "            ) \n",
    "            for action in tqdm(action_list.to_dict(orient='records'),desc='Action details')]\n",
    "        action_details = pd.json_normalize([ad for ad in ads if ad is not None])\n",
    "\n",
    "        action_details.to_excel(xlsx, sheet_name='Actions')\n",
    "        logger.info(f'Action SMARTs...')\n",
    "\n",
    "        smarts = [query_action_SMART(\n",
    "                action=action,\n",
    "                llm=llm,\n",
    "                vector_store=vector_store, \n",
    "                logger=logger,\n",
    "                city = city\n",
    "            ) for action in tqdm(action_list.to_dict(orient='records'),desc='Action SMART')]\n",
    "        action_SMART = pd.json_normalize([sm for sm in smarts if sm is not None])\n",
    "\n",
    "        action_SMART.to_excel(xlsx, sheet_name='Actions_SMART')\n",
    "\n",
    "for city in ['Firenze']:#list(config.keys()):\n",
    "    pdf_to_excel(\n",
    "        city, \n",
    "        f'output/{city}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Firenze'\n",
    "files = [f'{pdf_prefix}{pdf[\"file\"]}' for pdf in config[city]['pdfs']]\n",
    "\n",
    "documents, splits = pdfs_to_documents(files)\n",
    "\n",
    "vector_store = documents_to_vector_store(documents, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Barrier(BaseModel):\n",
    "    title: str\n",
    "    brief_description: str\n",
    "    page_reference: str\n",
    "    explanation: str\n",
    "    category: List[Literal[\"Leadership\", \"Financial\", \"Regulatory\", \"Operational\", \"Organisational\", \"Partnerships\", \"Social\", \"Environmental\", \"Safety and Security\", \"Other\"]]\n",
    "\n",
    "class BarrierList(BaseModel):\n",
    "    barriers: List[Barrier]\n",
    "\n",
    "\n",
    "response = ask_RAG(\n",
    "    embed_query = '''Identify text segments that describe obstacles, limitations, or difficulties in implementing the SECAP or achieving emission reduction targets. \n",
    "    Focus on segments describing: \"barrier\", \"challenge\", \"weakness\", \"lack of\", \"difficulty/difficulties\", \"insufficient/insufficiency\", \"inadequate/inadequacy\",\n",
    "    \"failure\", \"underestimation\", \"burden\" when they specifically relate to plan implementation or target achievement. \n",
    "    \n",
    "    Exclude mentions of barriers that only apply to specific individual actions.''',\n",
    "    vector_store = vector_store,\n",
    "    response_model=BarrierList,\n",
    "    llm = llm,\n",
    "    logger = logger,\n",
    "    template_key = 'barriers_prompt',\n",
    "    template_kwargs={},\n",
    "    city = city,\n",
    "    k=50\n",
    ")\n",
    "bars = pd.DataFrame([b for b in response['barriers']])\n",
    "bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plgrnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
