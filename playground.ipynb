{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from llm import load_models\n",
    "from dotenv import load_dotenv\n",
    "from questioning import load_qdf, ask_qdfs, pdf_to_documents, documents_to_vector_store, query_action_detail, query_action_list, ask_RAG\n",
    "import json\n",
    "from logging_config import logging_config\n",
    "logger = logging_config(f'GPT@JRC','logger.log')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "action_page_limit = {\n",
    "    'Torino.pdf': (143, 191),\n",
    "    'Zaragoza.pdf': (0, 200),\n",
    "    'Bologna.pdf': (128, 194),\n",
    "    'Izmir.pdf': (58, 142)\n",
    "}\n",
    "\n",
    "load_dotenv()\n",
    "llm, emb = load_models(service = 'GPT@JRC')\n",
    "qdf = load_qdf() # questions from JSON\n",
    "pdf_prefix='pdf_input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_to_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTorino.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m document, documents \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_to_documents\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m documents_to_vector_store(documents, emb)\n\u001b[1;32m      5\u001b[0m action_list \u001b[38;5;241m=\u001b[39m query_action_list(\n\u001b[1;32m      6\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm, \n\u001b[1;32m      7\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pdf_to_documents' is not defined"
     ]
    }
   ],
   "source": [
    "pdf = 'Torino.pdf'\n",
    "document, documents = pdf_to_documents(f'{pdf_prefix}{pdf}')\n",
    "vector_store = documents_to_vector_store(documents, emb)\n",
    "\n",
    "action_list = query_action_list(\n",
    "    llm=llm, \n",
    "    documents=documents,\n",
    "    page_start= action_page_limit[pdf][0],\n",
    "    page_end=action_page_limit[pdf][1],\n",
    "    logger=logger\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_excel(pdf, excel_output, llm=llm, emb=emb, pdf_prefix='pdf_input/'):\n",
    "    logger.info(f'Starting PDF {pdf}')    \n",
    "    logger.debug('Reading the documents..')\n",
    "    document, documents = pdf_to_documents(f'{pdf_prefix}{pdf}')\n",
    "    \n",
    "    logger.debug('Converting to vector store ...')\n",
    "    vector_store = documents_to_vector_store(documents, emb)\n",
    "\n",
    "    with pd.ExcelWriter(excel_output) as xlsx:\n",
    "\n",
    "        qs_responses = ask_qdfs(\n",
    "            qdf = qdf,\n",
    "            llm = llm, \n",
    "            vector_store = vector_store,\n",
    "            pdf = pdf,\n",
    "            logger=logger\n",
    "        )\n",
    "\n",
    "        qs_responses.to_excel(xlsx,sheet_name='standard_qs')\n",
    "\n",
    "        bars = pd.DataFrame(ask_RAG(\n",
    "            embed_query = 'List all barriers to accelerating emission reduction in view of the 2030 climate-neutrality goal that are explicitly described in the plan',\n",
    "            vector_store = vector_store,\n",
    "            llm = llm,\n",
    "            logger = logger,\n",
    "            template_key = 'barriers_prompt',\n",
    "            template_kwargs={},\n",
    "            pdf = pdf\n",
    "        ))\n",
    "        bars.to_excel(xlsx, sheet_name = 'barriers')\n",
    "\n",
    "        \n",
    "        participatory_processes = pd.DataFrame(ask_RAG(\n",
    "            embed_query='''\n",
    "            - List all participatory process described in the SECAP plan.\n",
    "            - Describe how citizens' contribute to specific priorities in the plan\n",
    "            - Inclusion of participatory processes and engagement of stakeholder\n",
    "            - Barriers to /challenges for citizen engagement and solutions/opportunities to remove it\n",
    "            ''',\n",
    "            template_key='participatory_processes',\n",
    "            template_kwargs={},\n",
    "            vector_store=vector_store,\n",
    "            llm=llm,\n",
    "            logger=logger,\n",
    "            pdf=pdf\n",
    "        ))\n",
    "        participatory_processes.to_excel(xlsx, sheet_name='participatory_processes')\n",
    "\n",
    "        logger.info(f'Starting actions in {pdf}')\n",
    "\n",
    "        action_list = query_action_list(\n",
    "            llm=llm, \n",
    "            documents=documents,\n",
    "            page_start= action_page_limit[pdf][0],\n",
    "            page_end=action_page_limit[pdf][1],\n",
    "            logger=logger\n",
    "        )\n",
    "        ads = [query_action_detail(\n",
    "                action=action, \n",
    "                template_key='action_details', \n",
    "                llm=llm, \n",
    "                vector_store=vector_store, \n",
    "                logger=logger,\n",
    "                pdf = pdf\n",
    "            ) \n",
    "            for action in tqdm(action_list,desc='Action details')]\n",
    "        action_details = pd.json_normalize([ad for ad in ads if ad is not None])\n",
    "\n",
    "        action_details.to_excel(xlsx, sheet_name='Actions')\n",
    "\n",
    "        smarts = [query_action_detail(\n",
    "                action=action,\n",
    "                template_key='action_SMART', \n",
    "                llm=llm,\n",
    "                vector_store=vector_store, \n",
    "                logger=logger,\n",
    "                pdf = pdf\n",
    "            ) for action in tqdm(action_list,desc='Action SMART')]\n",
    "        action_SMART = pd.json_normalize([sm for sm in smarts if sm is not None])\n",
    "\n",
    "        action_SMART.to_excel(xlsx, sheet_name='Actions_SMART')\n",
    "\n",
    "for pdf in ['Torino.pdf','Izmir.pdf']:\n",
    "    pdf_to_excel(pdf, f'output/{pdf.replace(\"pdf\",\"xlsx\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plgrnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
